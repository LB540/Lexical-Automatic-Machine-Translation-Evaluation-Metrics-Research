{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"jGZQLM8vnJ13","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682356301477,"user_tz":-330,"elapsed":30819,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"ca55ac57-451e-467a-e0c1-59759e976624"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCHOSJTOnAY5","outputId":"1a79a33a-f1d8-4abd-c470-e8539f19007d","executionInfo":{"status":"ok","timestamp":1682356305127,"user_tz":-330,"elapsed":3658,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["import nltk.data\n","from nltk.tokenize import BlanklineTokenizer\n","import sys\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"krfeO9Anm3Vu","executionInfo":{"status":"ok","timestamp":1682356308275,"user_tz":-330,"elapsed":5,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[],"source":["# test = open(\"/content/drive/MyDrive/Hybridization/input/en-hi-wsd-3L/output_en-hi_WSD-500_intrain.txt\", \"r\")\n","# reference = open(\"/content/drive/MyDrive/Hybridization/output/en-hi/ref_en-hi-500-intrain.txt\", \"r\")\n","# reference = open(\"/content/drive/MyDrive/MTE_Files/METEOR/parallel-n/english.txt\",\"r\")\n","# test = open(\"/content/drive/MyDrive/MTE_Files/METEOR/parallel-n/hindi.txt\",\"r\")\n","\n","# reference = open(\"/content/drive/MyDrive/MTdata/references(human).txt\")\n","# test = open(\"/content/drive/MyDrive/MTdata/hypothesis(machine).txt\")\n","\n","# reference = open(\"/content/drive/MyDrive/MTdata/benRef.txt\")\n","# test = open(\"/content/drive/MyDrive/MTdata/benHyp.txt\")\n","\n","reference = open(\"/content/drive/MyDrive/MTdata/Telugu/ref.txt\")\n","test = open(\"/content/drive/MyDrive/MTdata/Telugu/yandex_hypo.txt\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"vX-kGR2rm3Vz","executionInfo":{"status":"ok","timestamp":1682356338916,"user_tz":-330,"elapsed":1030,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[],"source":["list1 = []\n","list2 = []\n","for line in reference:\n","    #print(line)\n","    list1.append(BlanklineTokenizer().tokenize(line))\n","for line in test:\n","    #print(line)\n","    list2.append(BlanklineTokenizer().tokenize(line))\n","reference.close()\n","test.close()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ce4GGgcUm3V4","executionInfo":{"status":"ok","timestamp":1682356338917,"user_tz":-330,"elapsed":8,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[],"source":["s1=[]\n","s2=[]\n","for ele in list1:\n","    for elem in ele:\n","        s1.append(\" \".join([str(elem) for elem in ele]))\n","for ele in list2:\n","    for elem in ele:\n","        s2.append(\" \".join([str(elem) for elem in ele]))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PdlTJyQ6m3V7","outputId":"054b27d5-16ae-41c0-c988-34edf214272f","executionInfo":{"status":"ok","timestamp":1682356339641,"user_tz":-330,"elapsed":11,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["27\n","27\n"]}],"source":["le=len(s2)\n","te = len(s1)\n","print(le)\n","print(te)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"o-46uTmum3WD","executionInfo":{"status":"ok","timestamp":1682356339642,"user_tz":-330,"elapsed":6,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[],"source":["from nltk.stem.porter import PorterStemmer\n","from nltk.corpus import wordnet\n","from itertools import chain, product\n","\n","\n","def _generate_enums(hypothesis, reference, preprocess=str.lower):\n","    hypothesis_list = list(enumerate(preprocess(hypothesis).split()))\n","    reference_list = list(enumerate(preprocess(reference).split()))\n","    return hypothesis_list, reference_list\n","\n","def _enum_stem_match(enum_hypothesis_list, enum_reference_list, stemmer = PorterStemmer()):\n","    stemmed_enum_list1 = [(word_pair[0],stemmer.stem(word_pair[1])) \\\n","                          for word_pair in enum_hypothesis_list]\n","\n","    stemmed_enum_list2 = [(word_pair[0],stemmer.stem(word_pair[1])) \\\n","                          for word_pair in enum_reference_list]\n","\n","    word_match, enum_unmat_hypo_list, enum_unmat_ref_list = \\\n","                    _match_enums(stemmed_enum_list1, stemmed_enum_list2)\n","\n","    enum_unmat_hypo_list = list(zip(*enum_unmat_hypo_list)) if len(enum_unmat_hypo_list)>0 else []\n","\n","    enum_unmat_ref_list = list(zip(*enum_unmat_ref_list)) if len(enum_unmat_ref_list)>0 else []\n","\n","    enum_hypothesis_list = list(filter(lambda x:x[0] not in enum_unmat_hypo_list,  \n","                                       enum_hypothesis_list))\n","\n","    enum_reference_list = list(filter(lambda x:x[0] not in enum_unmat_ref_list, \n","                                      enum_reference_list))\n","\n","    return word_match, enum_hypothesis_list, enum_reference_list\n","\n","\n","\n","\n","def _match_enums(enum_hypothesis_list, enum_reference_list):\n","    word_match = []\n","    for i in range(len(enum_hypothesis_list))[::-1]:\n","        for j in range(len(enum_reference_list))[::-1]:\n","            if enum_hypothesis_list[i][1] == enum_reference_list[j][1]:\n","                word_match.append((enum_hypothesis_list[i][0],enum_reference_list[j][0]))\n","                (enum_hypothesis_list.pop(i)[1],enum_reference_list.pop(j)[1])\n","                break\n","    return word_match, enum_hypothesis_list, enum_reference_list\n","\n","\n","def _enum_wordnetsyn_match(enum_hypothesis_list, enum_reference_list, wordnet = wordnet):\n","    word_match = []\n","    for i in range(len(enum_hypothesis_list))[::-1]:\n","        hypothesis_syns = set(chain(*[[lemma.name() for lemma in synset.lemmas() \n","                                        if lemma.name().find('_')<0] \n","                                       for synset in \\\n","                                           wordnet.synsets(\n","                                               enum_hypothesis_list[i][1])]\n","                                               )).union({enum_hypothesis_list[i][1]})\n","        for j in range(len(enum_reference_list))[::-1]:\n","            if enum_reference_list[j][1] in hypothesis_syns:\n","                word_match.append((enum_hypothesis_list[i][0],enum_reference_list[j][0]))\n","                enum_hypothesis_list.pop(i),enum_reference_list.pop(j)\n","                break\n","    return word_match, enum_hypothesis_list, enum_reference_list\n","\n","\n","def _count_chunks(matches):\n","    i=0\n","    chunks = 1\n","    while(i<len(matches)-1):\n","        if (matches[i+1][0]==matches[i][0]+1) and (matches[i+1][1]==matches[i][1]+1):\n","            i+=1\n","            continue\n","        i+=1\n","        chunks += 1\n","    return chunks\n","\n","\n","\n","\n","\n","\n","def _enum_allign_words(enum_hypothesis_list, enum_reference_list, \n","                       stemmer=PorterStemmer(), wordnet = wordnet):\n","    exact_matches, enum_hypothesis_list, enum_reference_list = \\\n","        _match_enums(enum_hypothesis_list, enum_reference_list)\n","\n","    stem_matches, enum_hypothesis_list, enum_reference_list = \\\n","        _enum_stem_match(enum_hypothesis_list, enum_reference_list,\n","                         stemmer = stemmer)\n","\n","    wns_matches, enum_hypothesis_list, enum_reference_list = \\\n","        _enum_wordnetsyn_match(enum_hypothesis_list, enum_reference_list, \n","                               wordnet = wordnet)\n","\n","    return (sorted(exact_matches + stem_matches + wns_matches, key=lambda wordpair:wordpair[0]),\n","            enum_hypothesis_list, enum_reference_list)\n","\n","\n","\n","\n","def single_meteor_score(reference, \n","                        hypothesis, \n","                        preprocess = str.lower, \n","                        stemmer = PorterStemmer(), \n","                        wordnet = wordnet, \n","                        alpha=0.9, \n","                        beta=3, \n","                        gamma=0.5):\n","    enum_hypothesis, enum_reference = _generate_enums(hypothesis, \n","                                                      reference, \n","                                                      preprocess = preprocess)\n","    #print(enum_hypothesis, enum_reference)\n","    \n","    translation_length = len(enum_hypothesis)\n","    reference_length = len(enum_reference)\n","    matches, _, _ = _enum_allign_words(enum_hypothesis, enum_reference)\n","    \n","    #print(matches, _, _)\n","    matches_count = len(matches)\n","    try:\n","        precision = float(matches_count)/translation_length\n","        recall = float(matches_count)/reference_length\n","        fmean = (precision*recall)/(alpha*precision+(1-alpha)*recall)\n","        chunk_count = float(_count_chunks(matches))\n","        frag_frac = chunk_count/matches_count\n","    except ZeroDivisionError:\n","        return 0.0        \n","    penalty = gamma*frag_frac**beta\n","    return (1-penalty)*fmean\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"G_9zD8Ctm3WM","executionInfo":{"status":"ok","timestamp":1682356345009,"user_tz":-330,"elapsed":3608,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[],"source":["lop=0\n","scor=[]\n","coun=0\n","for lop in range(le):\n","    scor.append(single_meteor_score(s1[lop],s2[lop]))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_ESQPGIm3WQ","outputId":"28dba24d-8640-4065-cf6a-1af9181945a2","executionInfo":{"status":"ok","timestamp":1682356345010,"user_tz":-330,"elapsed":10,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1.   0.3896604938271605\n","2.   0.33848417954378224\n","3.   0.12139423076923078\n","4.   0.755560651226783\n","5.   0.5033238366571701\n","6.   0.14705882352941174\n","7.   0.4445422535211268\n","8.   0.04132231404958677\n","9.   0.25833333333333336\n","10.   0.3468406593406593\n","11.   0.40812807881773394\n","12.   0.3647058823529412\n","13.   0.6916666666666668\n","14.   0.5\n","15.   0.20444444444444443\n","16.   0.5506172839506173\n","17.   0.08971291866028708\n","18.   0.47700840937555916\n","19.   0.04201680672268908\n","20.   0.5367768595041322\n","21.   0.12820512820512822\n","22.   0.2508169934640523\n","23.   0.36666666666666664\n","24.   0.5575\n","25.   0.4310344827586206\n","26.   0.43945312499999994\n","27.   0.42613636363636365\n"]},{"output_type":"execute_result","data":{"text/plain":["0.3633855883712647"]},"metadata":{},"execution_count":10}],"source":["f1 = open('/content/meteor_blank_score_ur1.txt', \"w\")\n","lope=0\n","su=0\n","for lope in range(le):\n","    print(f\"{lope+1}.   {scor[lope]}\")\n","    su=su+scor[lope]\n","    f1.write(str(scor[lope])+'\\n') #Sentence_score\n","f1.close()\n","su=su/le\n","su #Corpus_score"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"v0JgG6ftTc0o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682356329948,"user_tz":-330,"elapsed":657,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"714f5800-a8d1-438c-a78f-ac8f74059b69"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["import nltk\n","from nltk import word_tokenize\n","\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"Gv31ocZQm3WW","outputId":"3ea9f22b-4fef-41ef-8944-0e7a1b2396e6","executionInfo":{"status":"error","timestamp":1682356436273,"user_tz":-330,"elapsed":1277,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-e5724da08c92>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/meteor_blank_score_ur1.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mlines1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlines2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not TextIOWrapper"]}],"source":["f5 = open('/content/meteor_blank_score_ur1.txt', \"a+\")\n","with open(test, \"r\") as f1, open(reference, \"r\") as f2:\n","  lines1 = [line.rstrip('\\n') for line in f1]\n","  print(len(lines1))\n","  lines2 = [line.rstrip('\\n') for line in f2]\n","  print(len(lines2))\n","  for l1,l2 in zip(lines1,lines2):\n","    tokens_ref=word_tokenize(l2)\n","    #print(tokens_ref)\n","    tokens_translate=word_tokenize(l1)\n","    #print(tokens_translate)\n","    score = nltk.translate.meteor_score.single_meteor_score(tokens_ref, tokens_translate)\n","    f5.write(str(score)+'\\n')\n","f5.close()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"doBWc18BgxHr","executionInfo":{"status":"ok","timestamp":1682356439723,"user_tz":-330,"elapsed":5,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[],"source":["from sklearn import preprocessing\n","import numpy as np"]},{"cell_type":"code","source":["file = \"/content/drive/MyDrive/MTdata/Telugu/yandex_metrics/meteor/meteor_blank_score_ur1-yt.txt\"\n","with open(file, 'r') as f:\n","  lines = [line.rstrip('\\n') for line in f]\n","  print(lines)\n","  lst_int = [float(i) for i in lines]\n","  print(lst_int)\n","  m_score = list(lst_int)\n","  # normalized_arr = preprocessing.normalize([lst_int])\n","  # print(type(normalized_arr))\n","  # print(type(list(normalized_arr[0])))\n","  # print(type(normalized_arr[0]))\n","  # m_score = list(normalized_arr[0])\n","  # print(m_score)\n","  # up_score = []\n","  # for i in m_score:\n","  #   up_score.append(i)\n","  # print(up_score)\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ykzs3oJk2U2","executionInfo":{"status":"ok","timestamp":1682356465147,"user_tz":-330,"elapsed":592,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"c51417d6-ec82-4297-eed9-52ee4455c879"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["['0.3896604938271605', '0.33848417954378224', '0.12139423076923078', '0.755560651226783', '0.5033238366571701', '0.14705882352941174', '0.4445422535211268', '0.04132231404958677', '0.25833333333333336', '0.3468406593406593', '0.40812807881773394', '0.3647058823529412', '0.6916666666666668', '0.5', '0.20444444444444443', '0.5506172839506173', '0.08971291866028708', '0.47700840937555916', '0.04201680672268908', '0.5367768595041322', '0.12820512820512822', '0.2508169934640523', '0.36666666666666664', '0.5575', '0.4310344827586206', '0.43945312499999994', '0.42613636363636365']\n","[0.3896604938271605, 0.33848417954378224, 0.12139423076923078, 0.755560651226783, 0.5033238366571701, 0.14705882352941174, 0.4445422535211268, 0.04132231404958677, 0.25833333333333336, 0.3468406593406593, 0.40812807881773394, 0.3647058823529412, 0.6916666666666668, 0.5, 0.20444444444444443, 0.5506172839506173, 0.08971291866028708, 0.47700840937555916, 0.04201680672268908, 0.5367768595041322, 0.12820512820512822, 0.2508169934640523, 0.36666666666666664, 0.5575, 0.4310344827586206, 0.43945312499999994, 0.42613636363636365]\n"]}]},{"cell_type":"code","source":["file = \"/content/drive/MyDrive/MTdata/Telugu/yandex_score.txt\"\n","with open(file, 'r') as f:\n","  lines = [line.rstrip('\\n') for line in f]\n","  lst_dble = [float(i) for i in lines]\n","  print((lst_dble))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NqkhlnCOk7vS","executionInfo":{"status":"ok","timestamp":1682356481926,"user_tz":-330,"elapsed":779,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"ad8a2aec-1a6a-4377-bca9-220b05be469a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.5, 0.8, 0.6, 0.9, 0.8, 0.5, 0.6, 0.4, 0.6, 0.7, 0.6, 0.7, 0.8, 0.5, 0.6, 0.8, 0.7, 0.7, 0.8, 0.3, 0.5, 0.6, 0.6, 0.5, 0.4, 0.5, 0.6]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from scipy.stats import pearsonr\n","\n","corr, _ = pearsonr(m_score, lst_dble)\n","print('Pearsons correlation: %.3f' % corr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GxsjNi8TlNaj","executionInfo":{"status":"ok","timestamp":1682356485057,"user_tz":-330,"elapsed":1002,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"e59ea933-dee8-49a5-faa9-ecbf55f4744f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Pearsons correlation: 0.226\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GHnD6sdHlZCb"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1tuClUQPRUc2ZdxF8gjT3f4vYmPrzzMQz","timestamp":1679232956617}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}