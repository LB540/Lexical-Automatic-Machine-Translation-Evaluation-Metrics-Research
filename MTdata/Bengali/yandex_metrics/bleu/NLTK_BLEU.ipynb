{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"XX79iDN_6xO3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682448433980,"user_tz":-330,"elapsed":28539,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"91b56088-4c15-4125-837f-ad33591d916e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VopY3sShdecN","executionInfo":{"status":"ok","timestamp":1682448670999,"user_tz":-330,"elapsed":2829,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"6fc0b7ff-c96f-4b40-e054-f75f4e479628"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":12687,"status":"error","timestamp":1682274535467,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"},"user_tz":-330},"id":"FLujb7SaWXjY","outputId":"454b5f70-a835-407d-e1e1-2c15f7e7e370"},"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c4a16733ae0a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/hindi_lang/model-final'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/reference.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/ref_pos\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [E050] Can't find model '/content/drive/MyDrive/hindi_lang/model-final'. It doesn't seem to be a Python package or a valid path to a data directory."]}],"source":["import spacy\n","nlp1 = spacy.load('/content/drive/MyDrive/hindi_lang/model-final')\n","\n","file1=\"/content/reference.txt\"\n","file2=\"/content/ref_pos\"\n","file3=\"/content/ref_dep\"\n","lines = [line.rstrip('\\n') for line in open(file1)]\n","\n","file_out=open(file2,\"w\")\n","file_out1=open(file3,\"w\")\n","for each_line in lines:\n","    doc = nlp1(each_line)\n","    #print(each_line)\n","    for token in doc:\n","        file_out.write(str(token.tag_))\n","        file_out.write(\" \")\n","        file_out1.write(str(token.dep_))\n","        file_out1.write(\" \")\n","    file_out.write(\"\\n\")\n","    file_out1.write(\"\\n\")\n","file_out.close()\n","file_out1.close()"]},{"cell_type":"markdown","metadata":{"id":"3NWdwRgO_U4P"},"source":["**SENETENCE WISE BLEU**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1882,"status":"ok","timestamp":1682448674339,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"},"user_tz":-330},"id":"KT3LaZkoxd9b","outputId":"951e246c-2445-4e56-f9d4-6aea11dbbf82"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.9/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.9/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]}],"source":["from nltk import word_tokenize\n","from nltk.translate.bleu_score import sentence_bleu\n","# translated_file = \"/content/drive/MyDrive/PhD/projectfolder/LM/Outputs/without_LM/En_Hi\"\n","# reference_file = \"/content/drive/MyDrive/PhD/projectfolder/LM/Outputs/hi_1000.txt\"\n","\n","# translated_file = \"/content/drive/MyDrive/MTE_Files/METEOR/parallel-n/hindi.txt\"\n","# reference_file = \"/content/drive/MyDrive/MTE_Files/METEOR/parallel-n/english.txt\"\n","\n","# translated_file = \"/content/drive/MyDrive/MTdata/hypothesis(machine).txt\"\n","# reference_file = \"/content/drive/MyDrive/MTdata/references(human).txt\"\n","\n","\n","# reference_file = \"/content/drive/MyDrive/MTdata/benRef.txt\"\n","# translated_file = \"/content/drive/MyDrive/MTdata/benHyp.txt\"\n","\n","\n","translated_file = \"/content/drive/MyDrive/MTdata/Bengali/benHyp(Machine) - Yandex translate.txt\"   # Bengali\n","reference_file=\"/content/drive/MyDrive/MTdata/Bengali/benRef(Human).txt\"\n","\n","\n","f5 = open('/content/BLEU-yb.txt', \"a+\")\n","with open(translated_file, \"r\") as f1, open(reference_file, \"r\") as f2:\n","  lines1 = [line.rstrip('\\n') for line in f1]\n","  #print(lines1)\n","  lines2 = [line.rstrip('\\n') for line in f2]\n","  #print(lines2)\n","  for l1,l2 in zip(lines1,lines2):\n","    tokens_ref=[word_tokenize(l2)]\n","    tokens_translate=word_tokenize(l1)\n","    score = sentence_bleu(tokens_ref, tokens_translate)\n","    f5.write(str(score)+'\\n')\n","f5.close()\n"]},{"cell_type":"markdown","metadata":{"id":"NpmT0w5vvHI8"},"source":["**CORPUS BLEU**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWhXIDk3Zq-A","outputId":"64639160-7011-465d-f9ef-caf7ac220afb"},"outputs":[{"name":"stdout","output_type":"stream","text":["3.220486919374789e-156\n"]}],"source":["import nltk\n","weights='0.25 0.25 0.25 0.25'\n","weight = [float(v) for v in weights.split()]\n","with open(\"/content/drive/MyDrive/PhD/projectfolder/LM/Outputs/kenlm/3L_2/en_hi/En_hn_kenlm_6\", 'r') as trans, open(\"/content/drive/MyDrive/PhD/projectfolder/LM/Outputs/hi_1000.txt\", 'r') as ref:\n","            tran_list, ref_list = [], []\n","            for tl in trans:\n","                rl = ref.readline()\n","                tran_list.append(tl.strip().split(' '))\n","                ref_list.append(rl.strip().split(' '))\n","print(nltk.translate.bleu_score.corpus_bleu(ref_list, tran_list, weight))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"bOznfvx9nzC_","executionInfo":{"status":"ok","timestamp":1682448676546,"user_tz":-330,"elapsed":12,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}}},"outputs":[],"source":["from sklearn import preprocessing\n","import numpy as np"]},{"cell_type":"code","source":["file = \"/content/drive/MyDrive/MTdata/Bengali/yandex_metrics/bleu/BLEU-yb.txt\"\n","with open(file, 'r') as f:\n","  lines = [line.rstrip('\\n') for line in f]\n","  print(lines)\n","  lst_int = [float(i) for i in lines]\n","  scaled = []\n","  for i in lst_int:\n","    val = (i - min(lst_int))/(max(lst_int)-min(lst_int))    # min-max scaling\n","    scaled.append(val)\n","  print(scaled)\n","  # normalized_arr = preprocessing.normalize([lst_int])\n","  # print(type(normalized_arr))\n","  # print(type(list(normalized_arr[0])))\n","  # print(type(normalized_arr[0]))\n","  # m_score = list(normalized_arr[0])\n","  # print(m_score)\n","  # up_score = []\n","  # for i in m_score:\n","  #   up_score.append(i)\n","  # print(up_score)\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1iRogDza_nF","executionInfo":{"status":"ok","timestamp":1682448677459,"user_tz":-330,"elapsed":923,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"d083f1de-7b01-44bf-bc35-00b2c91287b4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['1.2183324802375697e-231', '5.253283993027542e-78', '6.668454445645829e-155', '1.0832677820940877e-231', '1.1368587676511996e-231', '6.484592771860512e-155', '1.0832677820940877e-231', '7.711523862191631e-155', '7.5314086239343e-155', '1.2882297539194154e-231', '1.2627076138080564e-231', '1.0832677820940877e-231', '1.1200407237786664e-231', '7.711523862191631e-155', '6.08970970641905e-155', '1.3483065280626046e-231', '1.2395288183339461e-231', '7.205735693881401e-155', '1.1008876702055895e-231', '6.480360213743594e-155', '7.053663163619216e-155']\n","[2.571052665775305e-155, 1.0, 1.2693877685837241e-77, 0.0, 1.0201425551757893e-155, 1.2343883902844835e-77, 0.0, 1.4679434564030433e-77, 1.4336572387730062e-77, 3.901597021926948e-155, 3.415764918708591e-155, 0.0, 6.999991192820676e-156, 1.4679434564030433e-77, 1.1592195880713206e-77, 5.045201179305961e-155, 2.974540048610677e-155, 1.3716630784563072e-77, 3.354071117207426e-156, 1.2335826927203436e-77, 1.3427149898960802e-77]\n"]}]},{"cell_type":"code","source":["file = \"/content/drive/MyDrive/MTdata/Bengali/score_yandex.txt\"\n","with open(file, 'r') as f:\n","  lines = [line.rstrip('\\n') for line in f]\n","  lst_dble = [float(i) for i in lines]\n","  print((lst_dble))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CvMbYu8tit7S","executionInfo":{"status":"ok","timestamp":1682448680857,"user_tz":-330,"elapsed":741,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"d3325ec9-154c-4705-ec8d-89dae94cd9f0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.4, 0.4, 0.6, 0.7, 0.4, 0.3, 0.3, 0.8, 0.4, 0.5, 0.9, 0.5, 0.3, 0.6, 0.6, 0.6, 0.7, 0.8, 0.6, 0.9, 0.6]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from scipy.stats import pearsonr\n","\n","corr, _ = pearsonr(scaled, lst_dble)\n","print('Pearsons correlation: %.3f' % corr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mm-wzYygjDQD","executionInfo":{"status":"ok","timestamp":1682448681481,"user_tz":-330,"elapsed":627,"user":{"displayName":"LALIT BISHT","userId":"16917600131278585489"}},"outputId":"ddf0fff4-2cdd-4d7d-b063-d7cb30ad9861"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Pearsons correlation: -0.203\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OMa9ieSojFt7"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"11gxjCE6oAJT6r6KzP4H-vLZxoRhQyh6k","timestamp":1679242441578}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}